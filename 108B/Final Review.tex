\documentclass[10pt]{article}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{amsxtra}
\usepackage{amsmath}
\usepackage{enumitem}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\ep}{\varepsilon}
\newcommand{\set}[1]{\left\{ #1\right\}}
\newenvironment{proof}{\noindent{\bf Proof.}}{\hfill $\square$\medskip}

\usepackage[utf8]{inputenc}


\title{Math 108B Final Review}
\author{Rad Mallari}

\begin{document}
\maketitle
\begin{enumerate}
    \item Prove that if $T$ has $k+1$ eigenvalues, then dim range $T\geq k$

    \begin{proof}
        We have $k+1$ distinct eigenvalues which imply that we have $k$ linearly independent vectors. Then there is at least $k$ nonzero eigenvalues, say $\lambda_{1},...,\lambda_{k}=0$. Letting $v_{j}$ be the eigenvector corresponding to $\lambda_{j}$ (where $1\leq j\leq k$), then $T(\frac{v_{j}}{\lambda_{j}})=\frac{1}{\lambda_{j}}T_{j}v_{j}=v_{j}\Rightarrow v_{j}\in\text{range }T\Rightarrow v_{1},...,v_{k}$ are l. ind.
    \end{proof}
    \item Prove that if $ST=TS$, then for every constant $\lambda$, the subspace $\text{null }(S-\lambda I)$ is invariant under $T$

    \begin{proof}
        Let $\lambda\in \mathbb{F}$, suppose $v\in\text{null }(S-\lambda I)$. Then $(S-\lambda I)(Tv)=(STv-\lambda Tv)=(TSv-\lambda Tv)=T(Sv-\lambda v)=0$. Therefore, $Tv\in\text{null}(S-\lambda I)$. Hence $\text{null}(S-\lambda I)$ is invariant under $T$.
    \end{proof}
    \item Prove that every nonzero vector is an eigenvalue of $T$, then $T=\lambda I$ for some constant $\lambda$.
    
    \begin{proof}
        For each $v\in V$, $\exists a_{v}\in\mathbb{F}$ s.t. $Tv=a_{v}v$. Since $T\cdot0=0$, we choose $a_{0}$ to be in $\mathbb{F}$, but for $v\in V\setminus\set{0}$, $a_{v}$ is unique. To show that $T$ is a scalar multiple of $I$, we sho that $a_{v}$ is indep. of $v$ for $v\in V\setminus\set{0}$. Suppose $v,w\in V\setminus\set{0}$, we w.t.s $a_{v}=a_{w}$. Case $1$: $(v,w)$ is lin. dep., then $\exists\lambda\in\mathbb{F}$ s.t. $w=\lambda v$ which implies $a_{w}w=Tw=T(\lambda w)=\lambda Tv=\lambda (a_{v}w)=a_{v}w\Rightarrow a_{v}=a_{w}$. Case $2$: $(v,w)$ lin. ind., we have $a_{v+w}(v+w)=T(v+w)=Tv+Tw=a_{v}v+a_{w}w$. This implies $(a_{v+w}-a_{v})v+(a_{v+w}-a_{w})w=0$, since $(v,w)$ lin. ind. this implies $a_{v+w}=a_{v}$ and $a_{v+w}=a_{w}$ and we conclude $a_{v}=a_{w}$. 
    \end{proof}
    \item Prove $P^{2}=P$, then $\text{null}P+\text{range}P=V\quad\text{null}P\cap\text{range}P=\set{0}$.
    
    \begin{proof}
        Suppose $v\in\text{null}P\cap\text{range}P$. Then $Pv=0$ and $\exists w\in V$ s.t. $v=Pw$. Applying $P$ to both sides, $Pv=P^{2}w=Pw$, but $Pv=0\Rightarrow Pw=0$. Because $v=Pw\Rightarrow v=0$. Since $v$ is arbitrary $\text{null}P\cap\text{range}P=0$. Suppose $v\in V$, then $v=(v-Pv)+Pv$. $P(v-Pv)=Pv-P^{2}v=0$, so $(v-Pv)\in\text{null}P$, hence $Pv\in\text{range}P$. Therefore, $v\in\text{null}P+\text{range}P$. $v\in V$ being arbitrary implies $v=\text{null}P+\text{range}P$.
    \end{proof}

    \item Let $V=\mathbb{R}^{4}$, $x_{1}=(1,0,4,2), x_{2}=(2,3,7,6)$. Find an orthonormal basis of $\text{span}(x_{1},x_{2})$.
    $$x_{4}=x_{2}-\frac{\langle x_{2},x_{1}\rangle}{\lVert x_{1}\rVert^{2}}x_{1}\quad\Rightarrow\quad x_{4}=(0,3,-1,2)\quad\Rightarrow\quad (\frac{1}{\sqrt{21}}x_{1},\frac{1}{\sqrt{14}}x_{4})$$

    \item Let $V=\mathbb{R}^{5}$, $x_{1}=(3,0,0,2,1)$, $x_{2}=(9,3,5,6,3)$. Same as $5$.
    $$x_{4}=x_{2}-3x_{1}=(0,3,5,0,0)\quad\Rightarrow\quad\langle\frac{x_{1}}{\lVert x_{1}\rVert},\frac{x_{4}}{\lVert x_{4}\rVert}\rangle\quad\Rightarrow\quad\left(\frac{x_{1}}{\sqrt{14}},\frac{x_{4}}{\sqrt{34}}\right)$$

    \item Let $V=\mathbb{R}^{4}$, $e_{1}=(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2})$, $e_{2}=(\frac{1}{\sqrt{2}},0,0,-\frac{1}{\sqrt{2}})$, $U=\text{span}(e_{1},e_{2})$.
        \begin{enumerate}[label=(\roman*)]
            \item Verify $(e_{1},e_{2})$ is an orthonormal basis of $U$.

            \begin{proof}
                Take the inner product, if $0$, then orthonormal.
            \end{proof}
            \item Find $x\in U$ s.t. $\lVert(1,2,3,4)-x\rVert=\text{minimal}$.

            \begin{proof}
                $\lVert y-x\rVert=\text{min}$
                \begin{equation}
                    \begin{split}
                        x&=\langle y,e_{1}\rangle e_{1}+\langle y,e_{2}\rangle e_{2}\\
                        &=\langle (1,2,3,4),(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2})\rangle(\frac{1}{2},\frac{1}{2},\frac{1}{2},\frac{1}{2})\\
                        +&\langle(1,2,3,4),(\frac{1}{\sqrt{2}},0,0,-\frac{1}{\sqrt{2}})\rangle(\frac{1}{\sqrt{2}},0,0,-\frac{1}{\sqrt{2}})\\
                        &=(1,\frac{5}{2},\frac{5}{2},1)\quad\text{(after number crunching)}
                    \end{split}
                \end{equation}
            \end{proof}
        \end{enumerate}
        \item Let $V$ the space consisting of real polynomials with the inner product $\langle p,q\rangle=\int_{0}^{1}p(x)q(x)dx$. Let $U=\text{span}(1,x,x^{2})$. Given that $(p_{0},p_{1},p_{2})$ orthonormal basis of $U$ where $p_{0}=1$, $p_{1}=\sqrt{12}\left(x-\frac{1}{2}\right)$, $p_{2}=\sqrt{180}\left(x^{2}-x+\frac{1}{6}\right)$. Find $p\in U$ such that $\lVert x^{4}-p\rVert=\text{minimal}$.
        
        \begin{proof}
            Let $x^{4}=p\Rightarrow p=\langle q,p_{0}\rangle p_{0}+\langle q,p_{1}\rangle p_{1}+\langle q,p_{2}\rangle p_{2}$
            $$\langle x^{4},p_{0}\rangle=\int_{0}^{4}x^{4}dx=\left[\frac{x^{5}}{5}\right]_{0}^{1}=\frac{1}{5}\quad\text{(repeat for $\langle x^{4},p_{1}\rangle$, $\langle x^{4},p_{2}\rangle$)}$$
            Then plug each inner product into $p$.
        \end{proof}
        \item Suppose $T$ is normal. Prove that $\lVert Tx\rVert=\lVert T^{*}x\rVert$ for every $x$.
        
        \begin{proof}
            $T$ normal implies 
            $$T^{*}T-T^{*}T=0\iff\langle(T^{*}T-TT^{*})v,v\rangle=0\quad \forall v\in V$$
            $$\iff\langle T^{*}Tv,v\rangle=\langle TT^{*}v,v\rangle\quad \forall v\in V$$
            $$\iff \lVert Tv\rVert^{2}=\lVert T^{*}v\rVert^{2}\quad\forall v\in V$$
        \end{proof}
        \item Suppose $T$ is self-adjoint. Let $\alpha,\beta\in\mathbb{R}$ such that $\alpha^{2}<\beta$. Prove the operator $T^{2}+2\alpha T+\beta I$ is invertible.
        
        \begin{proof}
            Let $v$ a nonzero in $V$. Then
            \begin{equation}
                \begin{split}
                    \langle (T^{2}+\alpha T+\beta I)v,v\rangle&=\langle T^{2}v+v\rangle+\alpha\langle Tv,v\rangle+\beta\langle v,v\rangle\\
                    &=\langle Tv,Tv\rangle +\alpha \langle Tv,v\rangle+\beta\lVert v\rVert^{2}\\
                    &\geq \lVert Tv\rVert^{2}-|\alpha|\lVert Tv\rVert\lVert v\rVert+\beta\lVert v\rVert^{2}\quad\text{(By Cauchy-Schwarz)}\\
                    &=\left(\lVert Tv\rVert-\frac{\lVert\alpha\rVert\lVert v\rVert}{2}\right)^{2}+\left(\beta-\frac{\alpha^{2}}{4}\right)\lVert v\rVert^{2}\\
                    &>0\quad\text{(implies $(T^{2}+\alpha T+\beta I)v\neq0$)}
                \end{split}
            \end{equation}
        So we can conclude that $T^{2}+\alpha T+\beta I$ is injective which implies $T^{2}+\alpha T+\beta I$ is invertible.
        \end{proof}
        \item Prove that for every $S$, the $S^{*}S$ is positive.
        
        \begin{proof}
            Let $T=S^{*}S$, then $T^{*}=(S^{*}S)^{*}=S^{*}(S^{*})^{*}=S^{*}S=T$, and therefore, $T$ is self-adjoint. Note that $\langle Tv,v\rangle=\langle S^{*}Sv,v\rangle=\langle Sv,Sv\rangle\geq 0\quad \forall v\in V$. Therefore, $T$ is positive.
        \end{proof}
        \item Suppose that $S$ is an isometry. Prove that $\langle Sx,Sy\rangle=\langle x,y\rangle$ for $x,y$.
        
        \begin{proof}
            Since $S$ is an isometry, $\forall u,v\in V$. 
            \begin{equation}
                \begin{split}
                    \langle Su,Sv\rangle&=\frac{(\lVert Su+Sv\rVert^{2}-\lVert Su-Sv\rVert^{2})}{4}\\
                    &=\frac{(\lVert S(u+v)\rVert^{2}-\lVert S(u-v)\rVert^{2})}{4}\\
                    &=\frac{(\lVert u+v\rVert^{2}-\lVert u-v\rVert^{2})}{4}\\
                    &=\langle u,v\rangle
                \end{split}
            \end{equation}
        Where second line is due to linearity of $S$ and third is due to isometry of $S$.
        \end{proof}
        \item Suppose $N$ is self-adjoint and nilpotent. Prove that $N=0$
        
        \begin{proof}
            Since $N$ is self-adjoint, $\exists$ an orthonormal basis $(e_{1},...,e_{n})$ of $V$ consisting of eigenvectors of $N$ by the spectral theorem. $N$ being nilpotent implies that $0$ is the only eigenvalue of $N$. Therefore, the eigenvalues corresponding to eache $e_{j}=0$ which implies $Ne_{j}=0\quad\forall e_{j}$. Because $(e_{1},...,e_{n})$ is the basis of $V$, $N=0$.
        \end{proof}

        \item Suppose that $\text{null}T^{3}\neq\text{null}T^{4}$. Prove that $\text{null}T\neq\text{null}T^{2}$.
        
        \begin{proof}
            Suppose $\text{null}T=\text{null}T^{2}$. We know the \textbf{Proposition 8.5} in the book that if $T\in\mathcal{L}(V)$ and $m$ is nonnegative integer s.t. $\text{null}T^{m}=\text{null}T^{m+1}$ then 
            $$\text{null}T^{0}\subset\text{null}T^{1}\subset...\subset\text{null}T^{m}=\text{null}T^{m}=\text{null}T^{m+1}=\text{null}T^{m+1}=...$$ therefore, by this proposition, $\text{null}T^{2}=\text{null}T^{4}$ which is a contradiction. So it must be the case that $\text{null}T^{2}\neq\text{null}T^{4}\Rightarrow\text{null}T\neq\text{null}T^{2}$
        \end{proof}
        
        \item Find minimal matrix that is
        \begin{enumerate}[label=\textbf{(\alph*)}]
            \item $4\times4$ with minimal polynomial $(z+1)^{2}(z-1)$.
            \item $5\times5$ with minimal polynomial $z(z-3)^{2}(z+4)$.
        \end{enumerate}

        \begin{proof}
        $$
        \textbf{(a) }\begin{bmatrix}
            \begin{bmatrix}
                -1&1\\
                0&-1
            \end{bmatrix}&\dots&0\\
                \vdots&
                \begin{bmatrix}
                    1
                \end{bmatrix}&0\\
                0&0&\begin{bmatrix}
                    0
                \end{bmatrix}
        \end{bmatrix}
        \quad\textbf{(b) }
        \begin{bmatrix}
            \begin{bmatrix}
                0&0\\
                0&0
            \end{bmatrix}&0&\dots&\dots&0\\
            0&0&\begin{bmatrix}
                3&1\\
                0&3
            \end{bmatrix}&\dots &0\\
            0 & 0 & 0 & \ddots & 0\\
            0 & 0 & \dots & 0 & -4
        \end{bmatrix}
        $$
        \end{proof}
        \item Find the minimal polynomial of:
        \begin{enumerate}[label=\textbf{(\alph*)}]
            \item $
            \begin{bmatrix}
                2&1&0&0&0\\
                0&2&1&0&0\\
                0&0&2&0&0\\
                0&0&0&2&0\\
                0&0&0&0&1
            \end{bmatrix}$
            \item 
            $\begin{bmatrix}
                3&1&0&0&0\\
                0&3&0&0&0\\
                0&0&-2&1&0\\
                0&0&0&-2&0\\
                0&0&0&0&4
            \end{bmatrix}$
        \end{enumerate}
        
        \begin{proof}
            \begin{enumerate}[label=\textbf{(\alph*)}]
                \item $(z-2)^{3}(z-1)$
                \item $(z-3)^{2}(z+3)^{2}(z-4)$
            \end{enumerate}
        \end{proof}

        
        \textbf{Gram-Schmidt:} For $\dim V=2$, $x_{1},x_{2}\in U$ are lin. ind.
        $$x_{3}=x_{1}-\frac{\langle x_{1},x_{2}\rangle}{\lVert x_{2}\rVert^{2}}x_{2}$$
        then $\langle x_{3},x_{2}\rangle=0 \text{(this is orthogonal)}$ and
        $$x_{4}=x_{2}-\frac{\langle x_{2},x_{1}\rangle}{\lVert x_{1}\rVert^{2}}x_{1}$$
        then $\langle x_{4},x_{1}\rangle=0$ is orthogonal.
        To find orthonormal basis $(y_{1},y_{2})$ of $U$:

        
        $$
        \text{Either}\quad
        \begin{cases}
            y_{1}=\frac{1}{\lVert x_{3}\rVert}x_{3}\\
            y_{2}=\frac{1}{\lVert x_{2}\rVert}x_{2}
        \end{cases}
        \qquad\text{Or}\quad
        \begin{cases}
            y_{1}=\frac{1}{\lVert x_{1}\rVert}x_{1}\\
            y_{2}=\frac{1}{\lVert x_{4}\rVert}x_{4}
        \end{cases}
        $$
    \end{enumerate}
\end{document}