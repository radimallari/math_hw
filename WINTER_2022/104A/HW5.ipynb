{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>\n",
    "    <center>\n",
    "        Math 104A Homework 5\n",
    "    </center>\n",
    "</h1>\n",
    "<h2>\n",
    "    <center>\n",
    "        Rad Mallari\n",
    "    <br>\n",
    "        8360828\n",
    "    </center>\n",
    "</h2>\n",
    "<br><br>\n",
    "<b>1.) The Discrete Fourier Transform (DFT)</b> is a periodic array $f_{j}$, for $j=0,...,N-1$ (corresponding to data at equally spaced point of the interval of\n",
    "periodicity) is evaluated via the Fast Fourier Transform (FFT) algorithm ($N$ power of $2$). Use FFT package, i.e. an already coded FFT (e.g scipy.fftpack or\n",
    "numpy.fft or fft() in matlab).\n",
    "<br>\n",
    "&emsp; <b>a.)</b> Which of the following expressions define the Fourier coefficients (DFT) that fits your package (name it) returns for $k = 0,...,N-1?$<br>\n",
    "&emsp;&emsp; (a) $c_{k}=\\sum_{j=1}^{N} f_{j}e^{-\\frac{i2\\pi kj}{N}}$ <br>\n",
    "&emsp;&emsp; (b) $c_{k}=\\sum_{j=1}^{N} f_{j}e^{-\\frac{i2\\pi k(j-1}{N}}$ <br>\n",
    "&emsp;&emsp; (c) $c_{k}=\\sum_{j=1}^{N-1} f_{j}e^{-\\frac{i2\\pi kj}{N}}$ <br>\n",
    "\n",
    "&emsp; <b>b.)</b>  Which of the following expressions define the inverse DFT computed by fft package?<br>\n",
    "&emsp;&emsp; (a) $c_{k}=\\sum_{j=1}^{N} f_{j}e^{-\\frac{i2\\pi kj}{N}}$ <br>\n",
    "&emsp;&emsp; (b) $c_{k}=\\sum_{j=1}^{N} f_{j}e^{-\\frac{i2\\pi k(j-1}{N}}$ <br>\n",
    "&emsp;&emsp; (c) $c_{k}=\\sum_{j=1}^{N-1} f_{j}e^{-\\frac{i2\\pi kj}{N}}$ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances between expression (a) points and numpy fft method:\n",
      "[0.307, 0.439, 0.738, 1.452, 0.673, 2.085, 1.254, 2.881, 0.573, 2.881, 1.254, 2.085, 0.673, 1.452, 0.738, 0.439]\n",
      "Distances between expression (b) points and numpy fft method:\n",
      "[0.0, 0.144, 0.971, 1.259, 0.785, 2.21, 1.554, 2.649, 0.266, 2.649, 1.554, 2.21, 0.785, 1.259, 0.971, 0.144]\n",
      "Distances between expression (c) points and numpy fft method:\n",
      "[0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307, 0.307]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import e, pi\n",
    "\n",
    "f_j = np.random.rand(\n",
    "    16,\n",
    ")\n",
    "N = len(f_j)\n",
    "\n",
    "package_fft_coeffs = list(np.fft.fft(f_j))\n",
    "\n",
    "a_expression_coeffs = [complex(0, 0) for n in range(N)]\n",
    "b_expression_coeffs = [complex(0, 0) for n in range(N)]\n",
    "c_expression_coeffs = [complex(0, 0) for n in range(N)]\n",
    "\n",
    "_2ipi = complex(0, -1) * 2 * pi\n",
    "\n",
    "# checking (a) c_k=SUM_j=1^N f_je^(-i2pikj/N)\n",
    "for k in range(N):\n",
    "    for j in range(1, N):\n",
    "        a_expression_coeffs[k] += f_j[j - 1] * e ** (_2ipi * k * j / N)\n",
    "# checking (b) c_k=SUM_j=0^N f_je^(-i2pik(j-1)/N)\n",
    "for k in range(N):\n",
    "    for j in range(N):\n",
    "        b_expression_coeffs[k] += f_j[j] * e ** (_2ipi * k * (j - 1) / N)\n",
    "# checking (c) c_k=SUM_j=0^N-1 f_je^(-i2pikj/N)\n",
    "for k in range(N):\n",
    "    for j in range(N - 1):\n",
    "        c_expression_coeffs[k] += f_j[j] * e ** (_2ipi * k * j / N)\n",
    "\n",
    "print(\"Distances between expression (a) points and numpy fft method:\")    \n",
    "print(\n",
    "    [\n",
    "        np.round(np.abs(a - t), 3)\n",
    "        for a, t in zip(a_expression_coeffs, package_fft_coeffs)\n",
    "    ]\n",
    ")\n",
    "print(\"Distances between expression (b) points and numpy fft method:\")\n",
    "print(\n",
    "    [\n",
    "        np.round(np.abs(b - t), 3)\n",
    "        for b, t in zip(b_expression_coeffs, package_fft_coeffs)\n",
    "    ]\n",
    ")\n",
    "print(\"Distances between expression (c) points and numpy fft method:\")\n",
    "print(\n",
    "    [\n",
    "        np.round(np.abs(c - t), 3)\n",
    "        for c, t in zip(c_expression_coeffs, package_fft_coeffs)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Rerunning the code multiple times, we see that the closest distance between the coefficients is consistently expression (c) </b>\n",
    "\n",
    "&emsp;b.)  Which of the following expressions define the inverse DFT computed by fft package?<br>\n",
    "&emsp;&emsp;(a) $c_{k}=\\sum_{j=1}^{N} f_{j}e^{-\\frac{i2\\pi kj}{N}}$ <br>\n",
    "&emsp;&emsp;(b) $c_{k}=\\sum_{j=1}^{N} f_{j}e^{-\\frac{i2\\pi k(j-1}{N}}$ <br>\n",
    "&emsp;&emsp;(c) $c_{k}=\\sum_{j=1}^{N-1} f_{j}e^{-\\frac{i2\\pi kj}{N}}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original f_j:\n",
      "[0.19647159 0.03475025 0.52094032 0.50341066 0.14813285 0.49364657\n",
      " 0.34428479 0.55751014 0.01505941 0.14826342 0.01221182 0.07814163\n",
      " 0.94361547 0.2282745  0.30350729 0.3073653 ]\n",
      "Distances between expression (a) points and original f_j\n",
      "[0.187, 0.034, 0.523, 0.502, 0.149, 0.496, 0.344, 0.558, 0.015, 0.149, 0.012, 0.081, 0.945, 0.227, 0.306, 0.307]\n",
      "Distances between expression (b) points and original f_j\n",
      "[0.176, 0.033, 0.526, 0.5, 0.15, 0.498, 0.344, 0.559, 0.016, 0.15, 0.012, 0.083, 0.946, 0.225, 0.309, 0.306]\n",
      "Distances between expression (c) points and original f_j\n",
      "[0.176, 0.033, 0.526, 0.5, 0.15, 0.498, 0.344, 0.559, 0.016, 0.15, 0.012, 0.083, 0.946, 0.225, 0.309, 0.306]\n"
     ]
    }
   ],
   "source": [
    "package_fft_coeffs = list(np.fft.ifft(f_j))\n",
    "a_expression_f_j = [complex(0, 0) for n in range(N)]\n",
    "b_expression_f_j = [complex(0, 0) for n in range(N)]\n",
    "c_expression_f_j = [complex(0, 0) for n in range(N)]\n",
    "\n",
    "\n",
    "# checking (a) f_j=2/N SUM_k=0^N-1 c_ke^i2pikj/N for j=0,1,...,N-1\n",
    "for j in range(N):\n",
    "    for k in range(N):\n",
    "        a_expression_f_j[j] += package_fft_coeffs[j] * e ** (-_2ipi * k * j / N)\n",
    "        a_expression_f_j[j] /= 2 * N\n",
    "# checking (b) f_j=1/N SUM_k=0^N-1 c_ke^i2pikj/N for j=0,1,...,N-1\n",
    "for j in range(N):\n",
    "    for k in range(N):\n",
    "        b_expression_f_j[j] += package_fft_coeffs[j] * e ** (-_2ipi * k * j\n",
    "                                                             / N)\n",
    "        b_expression_f_j[j] /= N\n",
    "# checking (c) f_j=1/N SUM_k=1^N c_ke^i2pikj/N for j=0,1,...,N-1\n",
    "for j in range(N):\n",
    "    for k in range(1, N):\n",
    "        c_expression_f_j[j] += package_fft_coeffs[j] * e ** (-_2ipi * k * j / N)\n",
    "        c_expression_f_j[j] /= N\n",
    "\n",
    "print(\"Original f_j:\")\n",
    "print(f_j)\n",
    "print(\"Distances between expression (a) points and original f_j\")\n",
    "print(\n",
    "    [\n",
    "        np.round(np.abs(a - t), 3)\n",
    "        for a, t in zip(a_expression_f_j, f_j)\n",
    "    ]\n",
    ")\n",
    "print(\"Distances between expression (b) points and original f_j\")\n",
    "print(\n",
    "    [\n",
    "        np.round(np.abs(b - t), 3)\n",
    "        for b, t in zip(b_expression_f_j, f_j)\n",
    "    ]\n",
    ")\n",
    "print(\"Distances between expression (c) points and original f_j\")\n",
    "print(\n",
    "    [\n",
    "        np.round(np.abs(c - t), 3)\n",
    "        for c, t in zip(c_expression_f_j, f_j)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Rerunning the code multiple times, we see that differences that expression (b) and (c) are consistenly similar, so it could be either.</b>\n",
    "<br><br>\n",
    "<b>2.)</b> Prove that if $f_{j}$ for $j=0,1,...,N-1$ are real numbers, then $c_{0}$ is real and $c_{N-k}=\\overline{c_{k}}$ where $\\overline{c_{k}}$ is the complex conjugate.<br>\n",
    "<b>Proof:</b><br>\n",
    "&emsp; We know that $c_{k}$ is given by:\n",
    "$$c_{k}=\\sum_{j=0}^{N-1}f_{j}e^{-2\\pi ikj/N}$$<br>\n",
    "&emsp; Therefore, letting $f_{j}\\in\\mathbb{R}$, then \n",
    "$$c_{0}=\\sum_{j=0}^{N-1}f_{j}e^{-2\\pi i\\cdot 0\\cdot j /N}=\\sum_{j=0}^{N-1}f_{j}e^{0}$$\n",
    "&emsp; Here we know that $e^{0}=1$ which is a real number, and since $f_{j}$ is assumed to be real, $c_{0}$ must be real.<br>\n",
    "&emsp; Furthermore, by the definition, we know:\n",
    "$$c_{N-k}=\\sum_{j=0}^{N-1}f_{j}e^{-2\\pi ij(N-k)/N}=\\sum_{j=0}^{N-1}f_{j}e^{-2\\pi ij}\\cdot e^{2\\pi ijk/N}$$\n",
    "&emsp; In class we proved that $e^{-2\\pi in}$ where $n\\in\\mathbb{Z}$ is $1$, therefore, we are left with:\n",
    "$$c_{N-k}=\\sum_{j=0}^{N-1}f_{j}e^{2\\pi ijk/N}$$\n",
    "&emsp; Meanwhile, $\\overline{c_{k}}$ is defined as:\n",
    "$$\\overline{c_{k}}=\\sum_{j=0}^{N-1}\\overline{f_{j}e^{-2\\pi ijk/N}}$$\n",
    "&emsp; Complex conjugate of $e^{-iz}$ is $e^{iz}$. Moreover, since $f_{j}$ is a real number then it stays the same, therefore:\n",
    "$$\\overline{c_{k}}=\\sum_{j=0}^{N-1}f_{j}e^{2\\pi ijk/N}$$\n",
    "&emsp; Which is exactly $c_{N-k}$ thereby proving $c_{N-k}=\\overline{c_{k}}$<br><br>\n",
    "\n",
    "<b>3.)</b> Recall the inner product axioms\n",
    "<ul>\n",
    "    <li>$\\langle f,h\\rangle=\\langle h,f\\rangle$\n",
    "    <li>$\\langle f,\\alpha h+\\beta g\\rangle=\\alpha\\langle f,h\\rangle+\\beta\\langle f,g\\rangle$\n",
    "    <li>$\\langle f,f\\rangle>0$ if $f\\neq0$\n",
    "    <li>$\\lVert f\\rVert=\\sqrt{\\langle f,f\\rangle}$\n",
    "</ul>\n",
    "&emsp; Suppose $\\{\\phi_{0}(x),\\phi_{1}(x),...,\\phi_{n}(x)\\}$ is an orthogonal set of functions with respect to the $L^{2}$ inner product, i.e.,\n",
    "$$\\langle\\phi_{j},\\phi_{k}\\rangle=\\int_{a}^{b}\\phi_{j}(x)\\phi_{k}(x)dx=0,\\quad j\\neq k$$\n",
    "&emsp; Using axioms of inner product to prove the Pythagorean theorem\n",
    "$$\\lVert\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rVert^{2}=\\lVert\\phi_{0}\\rVert^{2}+\\lVert\\phi_{1}\\rVert^{2}+...+\\lVert\\phi_{n}\\rVert^{2}$$\n",
    "<b>Proof:</b><br>\n",
    "&emsp; By the last axiom, the left side of the equation is given by:\n",
    "$$\\lVert\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rVert^{2}=\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rangle$$\n",
    "&emsp; Then by the second axiom:\n",
    "$$\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rangle=\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{0}\\rangle+\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{1}\\rangle+...+\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{n}\\rangle$$\n",
    "&emsp; And by the first axiom, we rewrite this as:\n",
    "$$\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{0}\\rangle+\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{1}\\rangle+...+\\langle\\phi_{0}+\\phi_{1}+...+\\phi_{n},\\phi_{n}\\rangle=\\langle\\phi_{0},\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rangle+\\langle\\phi_{1},\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rangle+...+\\langle\\phi_{n},\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rangle$$\n",
    "&emsp; Repeating these steps yields:\n",
    "$$\\langle\\phi_{0},\\phi_{0}\\rangle+\\langle\\phi_{0},\\phi_{1}\\rangle+...+\\langle\\phi_{0},\\phi_{n}\\rangle+\\langle\\phi_{1},\\phi_{0}\\rangle+\\langle\\phi_{1},\\phi_{1}\\rangle+...+\\langle\\phi_{1},\\phi_{n}\\rangle+\\langle\\phi_{n},\\phi_{0}\\rangle+\\langle\\phi_{n},\\phi_{1}\\rangle+...+\\langle\\phi_{n},\\phi_{n}\\rangle$$\n",
    "&emsp; Since our $\\phi$s are orthogonal functions, the inner products between $\\phi$'s that do not have the same index will be $0$ and we are left with:\n",
    "$$\\langle\\phi_{0},\\phi_{0}\\rangle+\\langle\\phi_{1},\\phi_{1}\\rangle+...+\\langle\\phi_{n},\\phi_{n}\\rangle$$\n",
    "&emsp; Which by the last axiom is equivalent to:\n",
    "$$\\langle\\phi_{0},\\phi_{0}\\rangle+\\langle\\phi_{1},\\phi_{1}\\rangle+...+\\langle\\phi_{n},\\phi_{n}\\rangle=\\lVert\\phi_{0}\\rVert^{2}+\\lVert\\phi_{1}\\rVert^{2}+...+\\lVert\\phi_{n}\\rVert^{2}$$\n",
    "&emsp; Proving that $\\lVert\\phi_{0}+\\phi_{1}+...+\\phi_{n}\\rVert^{2}=\\lVert\\phi_{0}\\rVert^{2}+\\lVert\\phi_{1}\\rVert^{2}+...+\\lVert\\phi_{n}\\rVert^{2}$<br><br>\n",
    "\n",
    "<b>4.)</b> Consider the inner product $\\int_{-1}^{1}f(x)g(x)dx$. Recall Legendre polynomials are obtained by orthogonalization of $\\{1,x,...,x^{n}\\}$.<br>\n",
    "&emsp; <b>a.)</b> Compute the first $4$ Legendre polynomials in $[-1,1]$.<br>\n",
    "&emsp; <b>b.)</b> Find the least squares polynomial approximations of degrees $1$, $2$, and $3$  for the function $f(x)=e^{x}$ on $[-1,1]$.<br>\n",
    "&emsp; <b>c.)</b> What is the least squares approximation of degree $3$ for $f(x)=x^{2}-x-1$ on $[-1,1]$? Explain.<br>\n",
    "<b>Proof:</b><br>\n",
    "&emsp; <b>a.)</b> We obtain this by the follow:<br>\n",
    "$$\\xi_{0}(x)=1$$\n",
    "$$\\xi_{1}(x)=x-\\alpha_{0},\\quad \\alpha_{0}=\\frac{\\langle x\\xi_{0},\\xi_{0}\\rangle}{\\langle\\xi_{0},\\xi_{0}\\rangle}=0\\Rightarrow \\xi_{1}(x)=x$$\n",
    "$$\\xi_{2}(x)=(x-\\alpha_{1})\\xi_{1}(x)-\\beta_{1}\\xi_{0}(x),\\quad \\alpha_{1}=\\frac{\\langle x\\xi_{0},\\xi_{0}\\rangle}{\\langle\\xi_{0},\\xi_{0}\\rangle}=0,\\quad\\beta_{1}=\\frac{\\langle x\\xi_{1},\\xi_{0}\\rangle}{\\langle\\xi_{0},\\xi_{0}\\rangle}=\\frac{1}{3}\\Rightarrow \\xi_{2}(x)=x^{2}-\\frac{1}{3}$$\n",
    "$$\\xi_{3}(x)=(x-\\alpha_{2})\\xi_{2}(x)-\\beta_{2}\\xi_{1}(x),\\quad \\alpha_{2}=\\frac{\\langle x\\xi_{1},\\xi_{1}\\rangle}{\\langle\\xi_{1},\\xi_{1}\\rangle}=0,\\quad\\beta_{2}=\\frac{\\langle x\\xi_{2},\\xi_{1}\\rangle}{\\langle\\xi_{1},\\xi_{1}\\rangle}=\\frac{4}{15}\\Rightarrow \\xi_{3}(x)=x^{3}-\\frac{3}{5}x$$\n",
    "&emsp; <b>b.)</b> Since we have an orthonormal system using the orthogonalization of $\\{1,x,...,x^{n}\\}$, our least squares polynomial approximation can be obtained using:\n",
    "$$\\sum_{i=1}^{n}c_{i}g_{i}$$\n",
    "&emsp; Where $n$ is our degree and $c_{i}=\\langle f,g\\rangle$. Therefore, we have:\n",
    "$$c_{0}=\\int_{-1}^{1}e^{x}dx=e^{-x}\\bigg|_{-1}^{1}=e-\\frac{1}{e}$$\n",
    "$$c_{1}=\\int_{-1}^{1}x\\cdot e^{x}dx=x\\cdot e^{-x}\\bigg|_{-1}^{1}-\\int_{-1}^{1}e^{x}dx=x\\cdot e^{-x}\\bigg|_{-1}^{1}-e^{x}\\bigg|_{-1}^{1}=\\frac{2}{e}$$\n",
    "$$c_{2}=\\int_{-1}^{1}\\left(x^{2}-\\frac{1}{3}e^{x}\\right)dx=x^{2}e^{x}\\bigg|_{-1}^{1}-2\\left[xe^{x}\\bigg|_{-1}^{1}-e^{x}\\bigg|_{-1}^{1}\\right]-\\frac{1}{3}(e^{x})\\bigg|_{-1}^{1}=\\frac{1}{3}\\left(2e-\\frac{14}{e}\\right)$$\n",
    "$$c_{3}=\\int_{-1}^{1}\\left(x^{3}-\\frac{3}{5}x\\right)e^{x}dx=x^{3}e^{x}\\bigg|_{-1}^{1}-3\\left[\\int_{-1}^{1}x^{2}e^{x}dx\\right]-\\frac{3}{5}\\int_{-1}^{1}xe^{x}dx=-2e+\\frac{74}{5e}$$\n",
    "&emsp; Therefore, our polynomial is given by:\n",
    "$$e^{x}\\approx e-\\frac{1}{e}+\\frac{2}{e}(x)+\\frac{1}{3}\\left(2e-\\frac{14}{e}\\right)\\left(x^{2}-\\frac{1}{3}\\right)+\\left(-2e+\\frac{74}{5e}\\right)\\left(x^{3}-\\frac{3}{5}x\\right)$$\n",
    "&emsp; <b>(c)</b> The least squares approximation of degree $3$ for $f(x)=x^{2}-x-1$ on $[-1,1]$ is exactly itself. This is because the Least-Squares Theory approximates a continuous function $f$ using some polynomial $p$<br>\n",
    "&emsp;&emsp;with degree at most $n$ that deviates as little as possible from $f$. This deviation is measured by $|f(x)-p(x)|$, and here it's clear that a polynomial with degree $3$ approximating a polynomial with degree $2$ that<br>\n",
    "&emsp;&emsp;deviates a little as possible would be the degree $2$ polynomial itself.<br><br>\n",
    "\n",
    "<b>5.)</b> Let $T_{n}(x)$ denote the Chebyshev polynomial on $[-1,1]$. Prove that\n",
    "$$\\frac{2}{\\pi}\\int_{-1}^{1}\\frac{T_{n}^{2}(x)}{\\sqrt{1-x^{2}}}dx=1$$\n",
    "<b>Proof:</b><br>\n",
    "&emsp; We define the Chebyshev polynomial for $x\\in [-1,1]$ to be:\n",
    "$$T_{n}(x)=\\cos(n\\cos^{-1}(x))\\quad(n\\geq0)$$\n",
    "&emsp; We have the property:\n",
    "$$T_{n}(\\cos\\theta)=\\cos(n\\theta)$$\n",
    "&emsp; where $\\theta\\in[0,\\pi]$, and $n\\in\\mathbb{N}$ Therefore, letting $x=\\cos\\theta\\Rightarrow dx=-sin\\theta d\\theta$, we rewrite the left side of our equation as:\n",
    "$$\\frac{2}{\\pi}\\int_{-1}^{1}\\frac{T_{n}^{2}(x)}{\\sqrt{1-x^{2}}}dx=\\frac{2}{\\pi}\\int_{\\pi}^{0}\\frac{(\\cos(n\\theta))^{2}}{\\sqrt{1-\\cos^{2}\\theta}}\\sin\\theta d\\theta$$\n",
    "&emsp; By trignometric identities, we know that $1-\\cos^{2}(\\theta)=\\sin^{2}(\\theta)$, which yields:\n",
    "$$\\frac{2}{\\pi}\\int_{\\pi}^{0}\\frac{(\\cos(n\\theta))^{2}}{\\sqrt{1-\\cos^{2}\\theta}}\\sin\\theta d\\theta=-\\frac{2}{\\pi}\\int_{\\pi}^{0}(\\cos(n\\theta))^{2}d\\theta$$\n",
    "&emsp; Using the double angle formula, we expand $\\cos^{2}(n\\theta)$ as:\n",
    "$$-\\frac{2}{\\pi}\\int_{\\pi}^{0}(\\cos(n\\theta))^{2}d\\theta=-\\frac{2}{\\pi}\\left(\\int_{\\pi}^{0}\\frac{1}{2}d\\theta+\\int_{\\pi}^{0}\\frac{\\cos(2n\\theta)}{2}d\\theta\\right)$$\n",
    "$$-\\frac{2}{\\pi}\\left(\\int_{\\pi}^{0}\\frac{1}{2}+\\int_{\\pi}^{0}\\frac{\\cos(2n\\theta)}{2}\\right)=-\\frac{2}{\\pi}\\left(\\frac{\\theta}{2}\\bigg|_{\\pi}^{0}+\\frac{1}{2}\\sin(2n\\theta)\\bigg|_{\\pi}^{0}\\right)$$\n",
    "$$-\\frac{2}{\\pi}\\left(\\frac{\\theta}{2}\\bigg|_{\\pi}^{0}+\\frac{1}{2}\\sin(2n\\theta)\\bigg|_{\\pi}^{0}\\right)=-\\frac{2}{\\pi}\\left(-\\frac{\\pi}{2}\\right)=1$$\n",
    "\n",
    "<b>6.)</b> Given a collection of data points $\\{(x_{i},y_{i}\\}_{i=1}^{m}$<br>\n",
    "&emsp; <b>a.)</b> Find the best least squares of the form $y=ax+bx^{2}$<br>\n",
    "&emsp; <b>b.)</b> Use the approximation to fit the data in Table 2 and find the error in the least square approximation.\n",
    "\n",
    "|$x_{j}$|$y_{j}$|\n",
    "|---|---|\n",
    "|$1$|$3.1$| \n",
    "|$2$|$9.8$|\n",
    "|$3$|$21.2$|\n",
    "|$4$|$36.1$|\n",
    "\n",
    "<b>Proof:</b><br>\n",
    "&emsp; <b>a.)</b> We use the general formula to minimize the least square of $a_{0},a_{1},...,a_{n}$, which is given by:\n",
    "$$E(a_{0},a_{1},...,a_{n})=\\sum_{i=1}^{m}\\left(y_{i}-P_{n}(x_{i})\\right)^{2}$$\n",
    "&emsp; Where $P_{n}$ is the polynomial of interest. Therefore, for our case, we have:\n",
    "$$E(a_{0},a_{1},a_{2})=\\sum_{i=1}^{m}\\left(y_{i}-P_{2}(x_{i})\\right)^{2}$$\n",
    "$$\\sum_{i=1}^{m}\\left(y_{i}-P_{2}(x_{i})\\right)^{2}=\\sum_{i=1}^{m}\\left(y_{i}-\\sum_{k=0}^{2}a_{k}x_{i}^{k}\\right)^{2}$$\n",
    "$$\\sum_{i=1}^{m}\\left(y_{i}-\\sum_{k=0}^{2}a_{k}x_{i}^{k}\\right)^{2}=\\sum_{i=1}^{m}\\left(y_{i}-a_{0}-a_{1}x_{i}-a_{2}x_{i}^{2}\\right)^{2}$$\n",
    "&emsp; Since $a_{0}=0$ in our case we are left with as our best least squares approximation:\n",
    "$$\\sum_{i=1}^{m}\\left(y_{i}-a_{1}x_{i}-a_{2}x_{i}^{2}\\right)^{2}$$\n",
    "&emsp; To solve this, we first take the partial derivatives with respect to each $a_{n}$:\n",
    "$$0=\\frac{\\partial E}{\\partial a_{1}}=2\\sum_{i=1}^{m}(y_{i}-a_{1}x_{i}-a_{2}x_{i}^{2})(-x_{i})$$\n",
    "$$0=\\frac{\\partial E}{\\partial a_{2}}=2\\sum_{i=1}^{m}(y_{i}-a_{1}x_{i}-a_{2}x_{i}^{2})(-x_{i}^{2})$$\n",
    "&emsp; This gives us our normal equations:\n",
    "$$\\sum_{i=1}^{m}a_{1}x_{i}^{2}+\\sum_{i=1}^{m}a_{2}x_{i}^{3}=\\sum_{i=1}^{m}x_{i}y_{i}$$\n",
    "$$\\sum_{i=1}^{m}a_{1}x_{i}^{3}+\\sum_{i=1}^{m}a_{1}x_{i}^{4}=\\sum_{i=1}^{m}x_{i}^{2}y_{i}$$\n",
    "\n",
    "&emsp; <b>b.)</b> Now to use this approximation to fit the data, we represent our normal equations in matrix form given by $A^{T}A\\vec{a}=A^{T}\\vec{b}$, where:\n",
    "$$A=\n",
    "\\begin{bmatrix}\n",
    "1 & x_{1} & x_{1}^{2} & \\dots & x_{1}^{n} \\\\\n",
    "1 & x_{2} & x_{2}^{2} & \\dots & x_{2}^{n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_{m} & x_{m}^{2} & \\dots & x_{m}^{n}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\mathrm{and}\\qquad\n",
    "\\vec{b}=\n",
    "\\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "y_{m}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "&emsp; For our problem we have:\n",
    "$$\n",
    "A=\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1^{2}\\\\\n",
    "1 & 2 & 2^{2}\\\\\n",
    "1 & 3 & 3^{2}\\\\\n",
    "1 & 4 & 4^{2}\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "A^{T}=\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & 1\\\\\n",
    "1 & 2 & 3 & 4\\\\\n",
    "1^{2} & 2^{2} & 3^{2} & 4^{2}\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\vec{b}=\n",
    "\\begin{bmatrix}\n",
    "3.1\\\\\n",
    "9.8\\\\\n",
    "21.2\\\\\n",
    "36.1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "&emsp; Computing the matrices:\n",
    "$$\n",
    "A^{T}A=\n",
    "\\begin{bmatrix}\n",
    "4 & 10 & 30\\\\\n",
    "10 & 30 & 100\\\\\n",
    "30 & 100 & 354\\\\\n",
    "\\end{bmatrix},\\qquad\n",
    "A^{T}b=\n",
    "\\begin{bmatrix}\n",
    "70.2\\\\\n",
    "230.7\\\\\n",
    "810.7\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "&emsp; This gives us $3$ equations:\n",
    "$$4a_{0}+10a_{1}+30a_{2}=70.2$$\n",
    "$$10a_{0}+30a_{1}+100a_{2}=230.7$$\n",
    "$$30a_{0}+100a_{1}+354a_{2}=810.7$$\n",
    "&emsp; Solving for our coefficients, gives us $a_{1}=0.96, a_{2}=2.017\\Rightarrow y=(0.96)x+(2.017)x^{2}$. For the errors, we have:\n",
    "<ul>\n",
    "    <li>$x=1$ the error is: $3.1-(0.96+2.017)=0.123$\n",
    "    <li>$x=2$ the error is: $9.8-(1.92+8.068)=-0.188$\n",
    "    <li>$x=3$ the error is: $21.2-(2.88+18.153)=0.167$\n",
    "    <li>$x=4$ the error is: $36.1-(3.84+32.272)=-0.012$\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
