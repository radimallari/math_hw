\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{amsxtra}
\usepackage{amsmath}
\usepackage{enumitem}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\ep}{\varepsilon}
\newcommand{\set}[1]{\left\{ #1\right\}}
\newenvironment{proof}{\noindent{\bf Proof.}}{\hfill $\square$\medskip}

\usepackage[utf8]{inputenc}


\title{Math 108B Homework 3}
\author{Rad Mallari}

\begin{document}
\maketitle
Let $V$ be an inner product space over $F$, and $T\in \mathcal{L}(V)$
\section{Problem 1}
Prove that if $U=\text{range }(T)$, then $U^{\perp}=\text{null }T^{*}$.

\begin{proof}
Suppose $T\in\mathcal{L}(V,W)$, and let $U=\text{max }T$. By a previous result,
$$w\in\text{null }T^{*}\Leftrightarrow T^{*}w=0$$
where $w\in W$, then
$$w\in\text{null }T^{*}\Leftrightarrow\langle v,T^{*}w\rangle=0\quad\forall v\in V$$
$$w\in\text{null }T^{*}\Leftrightarrow\langle Tv,w\rangle=0\quad\forall v\in V$$
$$w\in\text{null }T^{*}\Leftrightarrow w\in(\text{range }T)^{\perp}=(U)^{\perp}$$
Thus we have $(U)^{\perp}=\text{null }T^{*}$.
\end{proof}


\newpage
\section{Problem 2}
Suppose $P\in\mathcal{L}(V)$ is such that $P^{2}=P$. Prove that $P$ is an orthogonal projection if and only if $P$ is self-adjoint.

\begin{proof}
For one direction, we assume that $P$ is a orthogonal projection. Then we use it's symmetry, denoted by $P_{u}$, where $u\in U$ and taking $w\in U^{\perp}$, $v\in V\Rightarrow v=u+w$. Taking two arbitrary $v$ we have $v_{1}=u_{1}+w_{1}$ and $v_{2}=u_{2}+w_{2}$ which results in
    
\begin{equation}
\begin{split}
\langle Pv_{1},v_{2}\rangle & =\langle u_{1},u_{2}+w_{2}\rangle \\
&=\langle u_{1}+u_{2}\rangle+\langle u_{1}+w_{2}\rangle \\
&=\langle u_{1},u_{2}\rangle \\
&=\langle u_{1},u_{2}\rangle+\langle w_{1},u_{2}\rangle \\
&=\langle u_{1},w_{1},u_{2}\rangle \\
&=\langle u_{1},Pv_{2}\rangle
\end{split}
\end{equation}

Hence $P=P^{*}$ and $P$ is self-adjoint.
For the other direction, we suppose that $P$ is self-adjoint. Then taking $v\in V$, we know that $P(v-Pv)=Pv-P^{2}v=0$ meaning
$$v-Pv\in\text{null }P=(\text{range }P^{*})^{\perp}=(\text{range }P)^{\perp}$$
by the homework, and we can manipulate to get
$$v=Pv+(v-Pv)$$
\end{proof}


\section{Problem 3}
Prove that if $T$ is normal, then $\text{range }T=\text{range }T^{*}$

\begin{proof}
Since $T$ is normal we know that
$$\text{range }T=(\text{null }T^{*})^{\perp}=(\text{null }T)^{\perp}=\text{range }T^{*}$$
\end{proof}


\section{Problem 4}
Prove that if $T$ is normal, then
$$\text{null }T^{k}=\text{null }T\quad \text{and}\quad \text{range }T^{k}=\text{range }T$$
for every positive integer $k$.

\begin{proof}
If $k=1$, then this is trivial, and now since $k$ is a positive integer, we consider $k\geq 2$. For the first, we know that if $v\in\text{null }T$, then $T^{k}v=T^{k-1}(Tv)=T^{k-1}0=0$.
Therefore, $v\in\text{null }T^{k}$ and so $\text{null }T\subset\text{null }T^{k}$. Similarly, for $TT^{*}=T^{*}T$, we follow
\begin{equation}
\begin{split}
\langle T^{*}T^{k-1}v,T^{k}T^{k-1}\rangle&=\langle T^{*}T^{k-1}v,T^{k-1}\rangle\\
&=\langle TvT^{k-1}\rangle\\
&=0
\end{split}
\end{equation}
This implies $T^{*}T^{k-1}v$ is orthogonal, meaning $T^{k-1}v$ is orthogonal by 7.4. By way of induction, $v\in \text{null }T^{k-1}\subset\text{null }T$ proves $\text{null }T^{k}=\text{null }T$.
For $\text{range }T$, we know $\text{range }T=Tv\quad\forall v\in V$. So, for $v\in\text{range }T^{k}$, there exists $w\in V$ such that $T^{k}w=V$ implying
$$V=T^{k}w=(T^{k-1})Tw\Rightarrow v\in\text{range }T$$
This result shows that $\text{range }T^{k}\subset\text{range }T$, now using
$$\dim V=\dim\text{null } T+\dim\text{range } T$$
we get
\begin{equation}
\begin{split}
\dim\text{range }T^{k}&=\dim V-\dim\text{null }T^{k}\\
&=\dim V-\dim\text{null }T\\
&=\dim\text{range }T
\end{split}
\end{equation}
So we conclude that $\text{range }T^{k}=\text{range }T$.
\end{proof}


\newpage
\section{Problem 5}
Prove that there does not exist a self-adjoint operator $T\in\mathcal{L}(\R^{3})$ such that $T(1,2,3)=(0,0,0)$ and $T(2,5,7)=(2,5,7)$

\begin{proof}
By way of contradiction, we suppose $T\in\mathcal{L}(\R^{3})$ where $T(1,2,3)=(0,0,0)$ and $T(2,5,3)=(2,5,7)$. Using $Tu=\lambda u$, we find the eigenvector $(1,2,3)$ has $\lambda_{1}=0$ and $(2,5,7)$ has $\lambda_{2}=1$. We assume that the corresponding eigenvectors of $T$ are orthogonal such that for $\alpha=\lambda_{1}=C$, $\beta=\lambda_{2}=1$, and $u=(1,2,3)$, $v=(2,5,7)$
$$(\alpha-\beta)\langle u,v\rangle=0$$
Because $\langle u,v\rangle\neq 0$, $T$ is not a self-adjoint operator. 
\end{proof}


\section{Problem 6}
Give a counterexample to show that the product of two self-adjoint operators is not necessarily self-adjoint.

\begin{proof}
We begin by letting $S,T\in\mathcal{L}(V^{2})$ be two operators with matrices
$$M(S)=
\begin{bmatrix}
    2&3\\
    3&7
\end{bmatrix}
\qquad
M(T)=
\begin{bmatrix}
0&1\\
1&0
\end{bmatrix}
$$
So $M(S^{*})=S$ and $M(J^{*})=T$. So,
$$
M(S)\cdot M(T)=
\begin{bmatrix}
3&3\\
2&7
\end{bmatrix}\neq
\begin{bmatrix}
3&2\\
3&7
\end{bmatrix}
$$
and the product is not necessarily self-adjoint.
\end{proof}


\section{Problem 7}
Suppose $F=\C$. Prove that a normal operator on $V$ is self-adjoint if and only if all its eigenvalues are real.

\begin{proof}
Letting $T\in\mathcal{L}(V)$ be normal. If $T$ is self-adjoint then every corresponding eigenvalue must be real by 7.1. Now, suppose all the eigenvalues of a normal $T\in\mathcal{L}(V)$ are real. By 7.9, we know $V$ gives us an orthonormal basis of the respective eigenvectors of $T$, specifically, $(e_{1},...,e_{n})\in V$. From this we obtain a diagonal matrix for $T$, and $T^{*}$ gives us a diagonal matrix as well. This implies that $T$ and $T^{*}$ commute and so $T$ must be self-adjoint.
\end{proof}


\section{Problem 8}
Suppose $F=\C$ and $T$ is a normal operator on $V$. Prove that there is a $S\in\mathcal{L}(V)$ such that $T=S^{2}$.

\begin{proof}
Letting $T\in\mathcal{L}(V)$ be a normal operator on the complex, inner-product space $V$. By 7.10, we know the orthonormal basis $(e_{1},...,e_{n})$ of $V$ consists of eigenvectors of $T$ such that $T(e_{j})=\lambda_{j^{\frac{1}{2}}}e_{j}$ such that each $\lambda_{j^{\frac{1}{2}}}$ represents the square root at every $\lambda_{j}$ of $T$. Then,
\begin{equation}
\begin{split}
T(e_{j})&=(\lambda_{j^{\frac{1}{2}}}e_{j})(\lambda_{j^{\frac{1}{2}}}e_{j})\\
&=(\lambda_{j^{\frac{1}{2}}}e_{j})^{2}
\end{split}
\end{equation}
implies $T=S^{2}$.
\end{proof}


\newpage
\section{Problem 9}
Prove that if $T$ is a positive operator on $V$, then $T^{k}$ is positive for every positive integer $k$.

\begin{proof}
Letting $T\in\mathcal{L}(V)$ be a positive operator on $V$, for an arbitrary $k\in\N$ (positive integers), implies that $T^{k}$ is self-adjoint by 7.24. Now looking at the case for when $k$ is even we have that $k=2n$ for $n\in\N$. By definition of positive operators, yields
\begin{equation}
\begin{split}
\langle T^{k}v\rangle&=\langle T^{2n}v,v\rangle\\
&=\langle T^{n}\cdot T^{n}v,v\rangle\\
&=\langle T^{n},T^{n}v\rangle\\
&\geq 0,\quad\forall v\in V
\end{split}
\end{equation}
Hence $T^{k}$ is positive.
Now for the case of when $k$ is odd, we know $k=2n+1$ for some $n\in\N$. By a similar process as the even case we have
\begin{equation}
\begin{split}
\langle Tv,v\rangle&=\langle T^{2n+1}v,v\rangle\\
&=\langle T(T^{2n}v),v\rangle\\
&=\langle T(T^{n}\cdot T^{n})v,v\rangle\\
&=\langle T(T^{n})v, T^{n}v\rangle\\
&\geq 0\quad\forall v\in V
\end{split}
\end{equation}
And again, $T>0\Rightarrow T^{k}$ is positive.
So for both cases $T^{k}$ is positive for all $k\in\N$.
\end{proof}


\newpage
\section{Problem 10}
Suppose $T$ is a positive operator on $V$. Prove that $T$ is invertible if and only if $\langle Tx,x\rangle$ is positive for $x\in V\setminus \set{0}$.

\begin{proof}
Letting $T$ be a positive operator on $V$, we assume that $T$ is invertible. Also, letting $x\in V\setminus \set{0}$ we have, by definition, a unique inverse of $T$ denoted by $T^{-1}\neq 0$. Using 7.26d yields
$$\exists S\in\mathcal{L}(V)\Rightarrow T=S^{*}S$$
and it follows that
\begin{equation}
\begin{split}
\langle Tx,x\rangle&=\langle S^{*}Sx,x\rangle\\
&=\langle Sx,Sx\rangle
\end{split}
\end{equation}

Since $T$ is invertible, $Tx\neq 0$, hence 
$$\langle Tx,x\rangle>0$$
Now assuming the converse, $\langle Tx,x\rangle$ is positive for all $x\in V\setminus\set{0}$, and letting $u\in V\setminus\set{0}$. Then by 3.17, where $Tx=Tu$, we observe that
$$x=T^{-1}(Tx)=T^{-1}(Tu)=u\cdot x=u$$
and we can conclude that $T$ is injective, and therefore invertible.
\end{proof}


\newpage
\section{Problem 11}
Prove that if $S\in\mathcal{L}(\R^{3})$ is an isometry, then there exists a nonzero vector $x\in\R^{3}$ such that $S^{2}x=x$.

\begin{proof}
Assume $S\in\mathcal{L}(R^{3})$ is an isometry, by definition $\left\|{Sv}\right\|=\left\|v\right\|$. 7.38 implies when $\R^{3}$ is an odd-dimnesional real inner-product space, there exists an orthonormal basis of $V$ with respect to $S$. Hence $S$ includes a block diagonal matrix where each block is of the form $\left |x\right |$ containing $1$ or $-1$ or a 2x2 matrix. And so, at least $1$ or $-1$ is an eigenvalue of $S$ and we can conclude that in either case $Sx=\lambda x$, that is
$$S^{2}x=S(Sx)=S(\lambda x)=\lambda(\lambda x)=\lambda^{2}x=x$$
\end{proof}

\end{document}